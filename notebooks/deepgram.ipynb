{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepgram import DeepgramClient, PrerecordedOptions, FileSource\n",
    "import requests\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import yt_dlp as youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "#mp4 directory\n",
    "SAVE_DIR = '/'.join(os.getcwd().split('/')[:3]) + '/speechdir'\n",
    "# Deepgram API key\n",
    "DG_KEY = os.getenv('DEEPGRAM_API_KEY')\n",
    "\n",
    "AUDIO_PATH = SAVE_DIR + '/audio_cont'\n",
    "\n",
    "\n",
    "ydl_opts = {\n",
    "  'format': 'best',\n",
    "  'outtmpl': AUDIO_PATH + '/%(title)s.%(ext)s',\n",
    "  'noplaylist': True,\n",
    "  'extract-audio': True,\n",
    "}\n",
    "\n",
    "video = \"https://www.youtube.com/watch?v=PeMlggyqz0Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_download(video_url: str = None, ydl_opts: dict = ydl_opts):\n",
    "    #if in SAVE_PATH have another file, delete it to be empty\n",
    "\tif os.path.exists(AUDIO_PATH):\n",
    "\t\tfor file in os.listdir(AUDIO_PATH):\n",
    "\t\t\tos.remove(AUDIO_PATH + '/' + file)\n",
    "\twith youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "\t\tinfo_dict = ydl.extract_info(video_url, download=True)\n",
    "\t\tvideo_url = info_dict.get(\"url\", None)\n",
    "\t\tvideo_title = info_dict.get('title', None)\n",
    "\t\tvideo_length = info_dict.get('duration')\n",
    "\treturn video_title, video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=PeMlggyqz0Y\n",
      "[youtube] PeMlggyqz0Y: Downloading webpage\n",
      "[youtube] PeMlggyqz0Y: Downloading tv client config\n",
      "[youtube] PeMlggyqz0Y: Downloading player c8dbda2a\n",
      "[youtube] PeMlggyqz0Y: Downloading tv player API JSON\n",
      "[youtube] PeMlggyqz0Y: Downloading ios player API JSON\n",
      "[youtube] PeMlggyqz0Y: Downloading m3u8 information\n",
      "[info] PeMlggyqz0Y: Downloading 1 format(s): 18\n",
      "[download] Destination: d:\\Project\\ThesisProd\\notebooks\\speechdir\\audio_cont\\Machine Learning Explained in 100 Seconds.mp4\n",
      "[download] 100% of    3.99MiB in 00:00:00 at 8.31MiB/s     \n"
     ]
    }
   ],
   "source": [
    "video_title, video_length = process_download(video, ydl_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = SAVE_DIR + '/json_cont'\n",
    "# URL of the audio file\n",
    "AUDIO_FILE = AUDIO_PATH + '/' + video_title + '.mp4'\n",
    "# Path to save the transcript JSON file\n",
    "TRANSCRIPT_FILE = JSON_PATH + '/' + video_title + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript():\n",
    "    try:\n",
    "        # STEP 1: Create a Deepgram client using the API key\n",
    "        deepgram = DeepgramClient(DG_KEY)\n",
    "\n",
    "        # Download the audio file from the URL\n",
    "        if os.path.exists(JSON_PATH):\n",
    "            for file in os.listdir(JSON_PATH):\n",
    "                os.remove(JSON_PATH + '/' + file)\n",
    "\n",
    "        with open(AUDIO_FILE, \"rb\") as file:\n",
    "            buffer_data = file.read()\n",
    "\n",
    "        payload: FileSource = {\n",
    "            \"buffer\": buffer_data,\n",
    "        }\n",
    "\n",
    "        # STEP 2: Configure Deepgram options for audio analysis\n",
    "        options = PrerecordedOptions(\n",
    "            model=\"nova-2\",\n",
    "            smart_format=True,\n",
    "        )\n",
    "\n",
    "        # STEP 3: Call the transcribe_file method with the text payload and options\n",
    "        response = deepgram.listen.prerecorded.v(\"1\").transcribe_file(payload, options)\n",
    "\n",
    "        # STEP 4: Write the response JSON to a file\n",
    "        with open(TRANSCRIPT_FILE, \"w\") as transcript_file:\n",
    "            transcript_file.write(response.to_json(indent=4))\n",
    "\n",
    "        print(\"Transcript JSON file generated successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23564\\839383143.py:25: DeprecatedWarning: prerecorded is deprecated as of 3.4.0 and will be removed in 4.0.0. deepgram.listen.prerecorded is deprecated. Use deepgram.listen.rest instead.\n",
      "  response = deepgram.listen.prerecorded.v(\"1\").transcribe_file(payload, options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript JSON file generated successfully.\n"
     ]
    }
   ],
   "source": [
    "transcript()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def print_transcript(transcription_file: str = None):\n",
    "    with open(transcription_file, \"r\") as file:\n",
    "        final_res = \"\"\n",
    "        data = json.load(file)\n",
    "        result = data['results']['channels'][0]['alternatives'][0]['transcript']\n",
    "        result = result.split('.')\n",
    "        for sentence in result:\n",
    "            final_res += sentence + '. '\n",
    "            # print(sentence + '.')\n",
    "        return final_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = print_transcript(TRANSCRIPT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Machine learning.  Teach a computer how to perform a task without explicitly programming it to perform said task.  Instead, feed data into an algorithm to gradually improve outcomes with experience, similar to how organic life learns.  The term was coined in 1959 by Arthur Samuel at IBM, who was developing artificial intelligence that could play checkers.  Half a century later, and predictive models are embedded in many of the products we use every day, which perform two fundamental jobs.  One is to classify data, like is there another car on the road, or does this patient have cancer? The other is to make predictions about future outcomes like will the stock go up or which YouTube video do you wanna watch next? The first step in the process is to acquire and clean up data.  Lots and lots of data.  The better the data represents the problem, the better the results.  Garbage in, garbage out.  The data needs to have some kind of signal to be valuable to the algorithm for making predictions.  And data scientists perform a job called feature engineering to transform raw data into features that better represent the underlying problem.  The next step is to separate the data into a training set and testing set.  The training data is fed into an algorithm to build a model, then the testing data is used to validate the accuracy or error of the model.  The next step is to choose an algorithm, which might be a simple statistical model like linear or logistic regression or a decision tree that assigns different weights to features in the data.  Or you might get fancy with a convolutional neural network, network, which is an algorithm that also assigns weights to features, but also takes the input data and creates additional features automatically.  And that's extremely useful for datasets that contain things like images or natural language, where manual feature engineering is virtually impossible.  Every one of these algorithms learns to get better by comparing its predictions to an error function.  If it's a classification problem, like is this animal a cat or a dog, the error function might be accuracy.  If it's a regression problem, like how much will a loaf of bread cost next year, then it might be mean absolute error.  Python is the language of choice among data scientists, but R and Julia are also popular options, and there are many supporting frameworks out there to make the process approachable.  The end result of the machine learning process is a model, which is just a file that takes some input data in the same shape that it was trained on, then spits out a prediction that tries to minimize the error that it was optimized for.  It can then be embedded on an actual device or deployed to the cloud to build a real world product.  This has been Machine Learning in one hundred seconds.  Like and subscribe if you wanna see more short videos like this, and leave a comment if you wanna see more machine learning content on this channel.  Thanks for watching, and I will see you in the next one. . \""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
